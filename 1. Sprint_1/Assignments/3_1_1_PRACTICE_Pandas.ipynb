{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1zZ80tdRQ4jK"
      },
      "source": [
        "---\n",
        "\n",
        "# 3. Pandas"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2qAlJy81Q4jK"
      },
      "source": [
        "Pandas is the best known Python library for manipulating and analyzing data. It is built on top of NumPy, so many features are similar. We will use Pandas to work with structured datasets.\n",
        "\n",
        "Just as NumPy provides us with arrays and with them we access many new features, Pandas provides us with DataFrames and Series. By far the most used object is the first one, DataFrames.\n",
        "\n",
        "We are going to use the open data of the Argentine government, so you will have to download the csv from the following link: [Names 2010-2014](https://www.datos.gob.ar/dataset/otros-nombres-personas-fisicas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "JY_I84c4Q4jL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A0xGFfvPQ4jL"
      },
      "source": [
        "## Reading a csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "OzmclufMQ4jL"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[97], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_names \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[0;32m      2\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mhttps://infra.datos.gob.ar/catalog/otros/dataset/2/distribution/2.20/download/nombres-2010-2014.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m df_names\n",
            "File \u001b[1;32md:\\AnyoneAI\\environment\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32md:\\AnyoneAI\\environment\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32md:\\AnyoneAI\\environment\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[1;32md:\\AnyoneAI\\environment\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[1;32md:\\AnyoneAI\\environment\\Lib\\site-packages\\pandas\\io\\common.py:716\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    713\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    715\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    717\u001b[0m     path_or_buf,\n\u001b[0;32m    718\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    719\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    720\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m    721\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    725\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
            "File \u001b[1;32md:\\AnyoneAI\\environment\\Lib\\site-packages\\pandas\\io\\common.py:373\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[39mif\u001b[39;00m content_encoding \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    371\u001b[0m             \u001b[39m# Override compression based on Content-Encoding header\u001b[39;00m\n\u001b[0;32m    372\u001b[0m             compression \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m--> 373\u001b[0m         reader \u001b[39m=\u001b[39m BytesIO(req\u001b[39m.\u001b[39;49mread())\n\u001b[0;32m    374\u001b[0m     \u001b[39mreturn\u001b[39;00m IOArgs(\n\u001b[0;32m    375\u001b[0m         filepath_or_buffer\u001b[39m=\u001b[39mreader,\n\u001b[0;32m    376\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    379\u001b[0m         mode\u001b[39m=\u001b[39mfsspec_mode,\n\u001b[0;32m    380\u001b[0m     )\n\u001b[0;32m    382\u001b[0m \u001b[39mif\u001b[39;00m is_fsspec_url(filepath_or_buffer):\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1008.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:482\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 482\u001b[0m         s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_safe_read(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlength)\n\u001b[0;32m    483\u001b[0m     \u001b[39mexcept\u001b[39;00m IncompleteRead:\n\u001b[0;32m    484\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1008.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:631\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_safe_read\u001b[39m(\u001b[39mself\u001b[39m, amt):\n\u001b[0;32m    625\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[39m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[39m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[0;32m    632\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m<\u001b[39m amt:\n\u001b[0;32m    633\u001b[0m         \u001b[39mraise\u001b[39;00m IncompleteRead(data, amt\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(data))\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1008.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1008.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1008.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "df_names = pd.read_csv(\n",
        "    \"https://infra.datos.gob.ar/catalog/otros/dataset/2/distribution/2.20/download/nombres-2010-2014.csv\"\n",
        ")\n",
        "df_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IYpCdXYu_nT"
      },
      "outputs": [],
      "source": [
        "df_names.dtypes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "slxR8rtXQ4jM"
      },
      "source": [
        "## Columns renaming"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mL3b7okLQ4jM"
      },
      "source": [
        "First of all let's rename the columns to `name`, `amount` and `year`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAFt31xGQ4jN"
      },
      "outputs": [],
      "source": [
        "df_names.rename(\n",
        "    columns={\"nombre\": \"name\", \"cantidad\": \"amount\", \"anio\": \"year\"}, inplace=True\n",
        ")\n",
        "df_names"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W-kRHmkOQ4jN"
      },
      "source": [
        "## Some Pandas useful functions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve4KOoEnQ4jN"
      },
      "source": [
        "**TODO:** Investigate the functions that are implemented in the next cell. What do they do? What do you think they can be useful for?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc9CkZwVQ4jO"
      },
      "outputs": [],
      "source": [
        "# df_names.head()\n",
        "# df_names.tail()\n",
        "# df_names.tail()\n",
        "# df_names.count()\n",
        "df_names.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u15ncIh3Q4jO"
      },
      "source": [
        "## Append a new row"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DyhUYuu2Q4jQ"
      },
      "source": [
        "**TODO:** Suppose that in the data load, someone forgot to add a name and its respective amount and year.\n",
        "\n",
        "Let's add to our dataset the following row with said information:\n",
        "\n",
        "Name: \"Daenerys Stormborn of the House Targaryen, First of Her Name de ella, the Unburnt, Queen of the Andals and the First Men, Khaleesi of the Great Grass Sea, Breaker of Chains, and Mother of Dragons\"\n",
        "\n",
        "Amount: 100\n",
        "Year: 2011"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_uvRquYQ4jR"
      },
      "outputs": [],
      "source": [
        "new_row = pd.DataFrame(\n",
        "    {\n",
        "        \"name\": [\n",
        "            \"Daenerys Stormborn of the House Targaryen, First of Her Name de ella, the Unburnt, Queen of the Andals and the First Men, Khaleesi of the Great Grass Sea, Breaker of Chains, and Mother of Dragons\"\n",
        "        ],\n",
        "        \"amount\": [100],\n",
        "        \"year\": [2011],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Concatenate the new DataFrame with the original DataFrame\n",
        "df_names = pd.concat([df_names, new_row], ignore_index=True)\n",
        "\n",
        "df_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete this cell with your code\n",
        "\n",
        "counts = df_names.groupby([\"name\", \"year\"]).sum()\n",
        "# filter for names with counts greater than 2000\n",
        "filtered_counts = counts[counts[\"count\"] > 2000]\n",
        "# reset the index to make the results easier to work with\n",
        "filtered_counts = filtered_counts.reset_index()\n",
        "# print the results\n",
        "filtered_counts"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vWsZ-dziQ4jR"
      },
      "source": [
        "**TODO:** Investigate the columns and index functions. What do they do? What data type is their output? What known data type do they resemble?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-dDWiEvQ4jS"
      },
      "outputs": [],
      "source": [
        "df_names.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI5UPDYwHING"
      },
      "outputs": [],
      "source": [
        "df_names.index"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PC8qZUapQ4jT"
      },
      "source": [
        "## Add a new column\n",
        "\n",
        "**TODO:** Add a column to the dataframe that corresponds to the number of characters in each name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIIicg1VQ4jU"
      },
      "outputs": [],
      "source": [
        "# Complete this cell with your code\n",
        "\n",
        "df_names[\"name_length\"] = df_names[\"name\"].apply(lambda x: len(x))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RDKEXbxhQ4jU"
      },
      "source": [
        "## Filtering by mask\n",
        "\n",
        "Its implementation is very similar in both NumPy and Pandas, so we will see how to do it first in NumPy then in Pandas.\n",
        "\n",
        "Suppose we make 100 rolls of a die, but we want to select only those rolls that were less than four. How can we do it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pRyLFwTQ4jV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "dice = np.random.randint(1, 7, size=100)\n",
        "print(dice)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fsZjUzBAQ4jW"
      },
      "source": [
        "What we can do is create a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xar0AoOSQ4jW"
      },
      "outputs": [],
      "source": [
        "mask = dice > 3\n",
        "print(mask)\n",
        "print(type(mask))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iahv1gBrQ4jW"
      },
      "outputs": [],
      "source": [
        "print(dice[mask])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0e40JjmQ4jX"
      },
      "outputs": [],
      "source": [
        "print(dice.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RsauVufQ4jX"
      },
      "outputs": [],
      "source": [
        "print(dice[dice > 3])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug5EdAFiQ4jX"
      },
      "source": [
        "**TODO:** Going back to our dataset, suppose we want to keep those rows with names that were repeated more than 2000 times in the corresponding year. Note that in the result a name may appear more than once in different years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88FRrCo6Q4jY",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Complete this cell with your code\n",
        "\n",
        "# Calculate the count of occurrences for each name-year combination\n",
        "df_names[\"count\"] = df_names.groupby([\"name\", \"year\"])[\"name\"].transform(\"count\")\n",
        "\n",
        "# Filter the DataFrame based on the count condition\n",
        "filtered_df = df_names[df_names[\"count\"] > 2000]\n",
        "\n",
        "# Display the filtered DataFrame\n",
        "filtered_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojll_QyOQ4jY"
      },
      "source": [
        ":**TODO:** What if we want to select those names with more than 8 characters and from 2010 onwards?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZljRV67DQ4jY"
      },
      "outputs": [],
      "source": [
        "# Complete this cell with your code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XEwO0yB4Q4jZ"
      },
      "source": [
        "## Statistics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YIkIyU8IQ4jZ"
      },
      "source": [
        "**TODO:** Obtain the mean value and standard deviation of each numeric column. Is there a function in Pandas that will give us even more statistics?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3GLbtlYQ4jZ"
      },
      "outputs": [],
      "source": [
        "# Complete this cell with your code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x9vfcdK0Q4jZ"
      },
      "source": [
        "## Delete a column"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LqOMcrjHQ4ja"
      },
      "source": [
        "**TODO:** Delete the column `amount_chars` from the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1EhPSujQ4ja"
      },
      "outputs": [],
      "source": [
        "# Complete this cell with your code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XE195QIAQ4ja"
      },
      "source": [
        "## Sorting by column"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GudaIbBhQ4ja"
      },
      "source": [
        "**TODO:** Sort the dataframe by `amount` and descending"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbH-kHiRQ4jb"
      },
      "outputs": [],
      "source": [
        "# Complete this cell with your code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5xpwZ5UnQ4jb"
      },
      "source": [
        "## Pandas groupby and plot"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WQwTuXNWQ4jb"
      },
      "source": [
        "**TODO:** Group the number of names by `year` and plot it using vertical bars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaT3BhtEQ4jb"
      },
      "outputs": [],
      "source": [
        "# Complete this cell with your code"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
