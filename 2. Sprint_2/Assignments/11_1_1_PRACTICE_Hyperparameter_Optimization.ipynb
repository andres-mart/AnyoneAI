{"cells":[{"cell_type":"markdown","metadata":{"id":"K7-BhkDtbW5B"},"source":["---\n","\n","# Let's practice\n","\n","Before you start working and playing with the different models that we have seen, we are going to download the dataset with which you are going to work, the titanic dataset, widely known and used in machine learning courses.\n","\n","For this we are going to do the following:\n","\n","```python\n","import numpy as np\n","import pandas as pd\n","from sklearn.datasets import fetch_openml\n","\n","titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=False)\n","df_titanic = pd.DataFrame(\n","    data=np.c_[titanic['data'], titanic['target']],\n","    columns= titanic['feature_names'] + ['target']\n",")\n","df_titanic = df_titanic.rename(columns={'target': 'survived'})\n","```\n","\n","So using the same dataset (Titanic), you should train 4 models:\n","\n","* Decision Tree\n","* SVM\n","* Random Forest\n","* Extra: XGBoost\n","\n","And you should apply the following concepts:\n","\n","* Train/Test Split.\n","* Feature engineering.\n","* GridSearch or RandomSearch with CV.\n","* Metrics."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"1b4oV1K4bW5B"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","from sklearn.svm import SVC\n","from matplotlib import style\n","from matplotlib import pyplot as plt\n","from sklearn.datasets import fetch_openml\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"elapsed":7589,"status":"ok","timestamp":1658934644727,"user":{"displayName":"Federico Morales","userId":"06983145799989655383"},"user_tz":180},"id":"cfiLRLLnbW5C","outputId":"2425852c-1076-4214-e1fa-896c2cba4b7e"},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\AnyoneAI\\environment\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>name</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>ticket</th>\n","      <th>fare</th>\n","      <th>cabin</th>\n","      <th>embarked</th>\n","      <th>boat</th>\n","      <th>body</th>\n","      <th>home.dest</th>\n","      <th>survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>Allen, Miss. Elisabeth Walton</td>\n","      <td>female</td>\n","      <td>29.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>24160</td>\n","      <td>211.3375</td>\n","      <td>B5</td>\n","      <td>S</td>\n","      <td>2</td>\n","      <td>None</td>\n","      <td>St Louis, MO</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>Allison, Master. Hudson Trevor</td>\n","      <td>male</td>\n","      <td>0.9167</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.55</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>Allison, Miss. Helen Loraine</td>\n","      <td>female</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.55</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>Allison, Mr. Hudson Joshua Creighton</td>\n","      <td>male</td>\n","      <td>30.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.55</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>None</td>\n","      <td>135.0</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n","      <td>female</td>\n","      <td>25.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>113781</td>\n","      <td>151.55</td>\n","      <td>C22 C26</td>\n","      <td>S</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>Montreal, PQ / Chesterville, ON</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  pclass                                             name     sex     age   \n","0    1.0                    Allen, Miss. Elisabeth Walton  female    29.0  \\\n","1    1.0                   Allison, Master. Hudson Trevor    male  0.9167   \n","2    1.0                     Allison, Miss. Helen Loraine  female     2.0   \n","3    1.0             Allison, Mr. Hudson Joshua Creighton    male    30.0   \n","4    1.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female    25.0   \n","\n","  sibsp parch  ticket      fare    cabin embarked  boat   body   \n","0   0.0   0.0   24160  211.3375       B5        S     2   None  \\\n","1   1.0   2.0  113781    151.55  C22 C26        S    11    NaN   \n","2   1.0   2.0  113781    151.55  C22 C26        S  None    NaN   \n","3   1.0   2.0  113781    151.55  C22 C26        S  None  135.0   \n","4   1.0   2.0  113781    151.55  C22 C26        S  None    NaN   \n","\n","                         home.dest survived  \n","0                     St Louis, MO        1  \n","1  Montreal, PQ / Chesterville, ON        1  \n","2  Montreal, PQ / Chesterville, ON        0  \n","3  Montreal, PQ / Chesterville, ON        0  \n","4  Montreal, PQ / Chesterville, ON        0  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=False)\n","df_titanic = pd.DataFrame(\n","    data=np.c_[titanic[\"data\"], titanic[\"target\"]],\n","    columns=titanic[\"feature_names\"] + [\"target\"],\n",")\n","df_titanic = df_titanic.rename(columns={\"target\": \"survived\"})\n","df_titanic.head()"]},{"cell_type":"markdown","metadata":{"id":"dYmo99ePbW5C"},"source":["## Exploration"]},{"cell_type":"markdown","metadata":{"id":"3RBgZPoUbW5D"},"source":["**TODO:** We always have to explore our datasets, so this is not going to be the exception."]},{"cell_type":"markdown","metadata":{},"source":["**The dataset contains the following columns:**\n","\n","1. pclass: Passenger's class (1st, 2nd, or 3rd class)\n","2. name: Passenger's name\n","3. sex: Passenger's gender (male or female)\n","4. age: Passenger's age\n","5. sibsp: Number of siblings/spouses aboard\n","6. parch: Number of parents/children aboard\n","7. ticket: Ticket number\n","8. fare: Fare paid by the passenger\n","9. cabin: Cabin number where the passenger stayed\n","10. embarked: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n","11. boat: Lifeboat number (if survived)\n","12. body: Body number (if not survived and body was recovered)\n","13. home.dest: Home or destination of the passenger\n","14. survived: Survival status (1 = survived, 0 = not survived)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["pclass          0\n","name            0\n","sex             0\n","age           263\n","sibsp           0\n","parch           0\n","ticket          0\n","fare            1\n","cabin        1014\n","embarked        2\n","boat          823\n","body         1188\n","home.dest     564\n","survived        0\n","dtype: int64\n"]}],"source":["# Check for missing values\n","print(df_titanic.isnull().sum())"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"QEk11PklbW5D"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1309 entries, 0 to 1308\n","Data columns (total 14 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   pclass     1309 non-null   object\n"," 1   name       1309 non-null   object\n"," 2   sex        1309 non-null   object\n"," 3   age        1046 non-null   object\n"," 4   sibsp      1309 non-null   object\n"," 5   parch      1309 non-null   object\n"," 6   ticket     1309 non-null   object\n"," 7   fare       1308 non-null   object\n"," 8   cabin      295 non-null    object\n"," 9   embarked   1307 non-null   object\n"," 10  boat       486 non-null    object\n"," 11  body       121 non-null    object\n"," 12  home.dest  745 non-null    object\n"," 13  survived   1309 non-null   object\n","dtypes: object(14)\n","memory usage: 143.3+ KB\n","None\n"]}],"source":["# We display basic information about the dataset\n","print(df_titanic.info())"]},{"cell_type":"markdown","metadata":{},"source":["It looks like the data types for some columns are currently listed as object instead of the appropriate data types. This could lead to issues when performing calculations and visualizations. Let's address this issue by converting the columns to their appropriate data types and then we proceed with the analysis. "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["parch\n","0.0    1002\n","1.0     170\n","2.0     113\n","3.0       8\n","4.0       6\n","5.0       6\n","6.0       2\n","9.0       2\n","Name: count, dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df_titanic[\"parch\"].value_counts()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>name</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>ticket</th>\n","      <th>fare</th>\n","      <th>cabin</th>\n","      <th>embarked</th>\n","      <th>boat</th>\n","      <th>body</th>\n","      <th>home.dest</th>\n","      <th>survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1309.0</td>\n","      <td>1309</td>\n","      <td>1309</td>\n","      <td>1046.0</td>\n","      <td>1309.0</td>\n","      <td>1309.0</td>\n","      <td>1309</td>\n","      <td>1308.00</td>\n","      <td>295</td>\n","      <td>1307</td>\n","      <td>486</td>\n","      <td>121.0</td>\n","      <td>745</td>\n","      <td>1309</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>3.0</td>\n","      <td>1307</td>\n","      <td>2</td>\n","      <td>98.0</td>\n","      <td>7.0</td>\n","      <td>8.0</td>\n","      <td>929</td>\n","      <td>281.00</td>\n","      <td>186</td>\n","      <td>3</td>\n","      <td>27</td>\n","      <td>121.0</td>\n","      <td>369</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>3.0</td>\n","      <td>Connolly, Miss. Kate</td>\n","      <td>male</td>\n","      <td>24.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>CA. 2343</td>\n","      <td>8.05</td>\n","      <td>C23 C25 C27</td>\n","      <td>S</td>\n","      <td>13</td>\n","      <td>135.0</td>\n","      <td>New York, NY</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>709.0</td>\n","      <td>2</td>\n","      <td>843</td>\n","      <td>47.0</td>\n","      <td>891.0</td>\n","      <td>1002.0</td>\n","      <td>11</td>\n","      <td>60.00</td>\n","      <td>6</td>\n","      <td>914</td>\n","      <td>39</td>\n","      <td>1.0</td>\n","      <td>64</td>\n","      <td>809</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        pclass                  name   sex     age   sibsp   parch    ticket   \n","count   1309.0                  1309  1309  1046.0  1309.0  1309.0      1309  \\\n","unique     3.0                  1307     2    98.0     7.0     8.0       929   \n","top        3.0  Connolly, Miss. Kate  male    24.0     0.0     0.0  CA. 2343   \n","freq     709.0                     2   843    47.0   891.0  1002.0        11   \n","\n","           fare        cabin embarked boat   body     home.dest survived  \n","count   1308.00          295     1307  486  121.0           745     1309  \n","unique   281.00          186        3   27  121.0           369        2  \n","top        8.05  C23 C25 C27        S   13  135.0  New York, NY        0  \n","freq      60.00            6      914   39    1.0            64      809  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Summary statistics\n","df_titanic.describe()"]},{"cell_type":"markdown","metadata":{"id":"ZNcYAm3ObW5D"},"source":["## Feature Engineering"]},{"cell_type":"markdown","metadata":{"id":"0cfciNS6bW5D"},"source":["**TODO:** \n","    \n","* Fill in the missing values using any criteria that you consider appropriate.\n","* Eliminate those features that you consider necessary.\n","* Format categorical features, using Label and/or Hot encoder."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0mOJrdplbW5E"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"8y1LtXG0bW5E"},"source":["## Hyperparameter Optimization"]},{"cell_type":"markdown","metadata":{"id":"cySyRIG_bW5E"},"source":["**TODO:**\n","\n","* Split the dataset into 80% train and 20% test.\n","* Using GridSearchCV or RandomSearchCV, tests different hyperparameter values for each model and chooses the best model from each of them.\n","* Evaluate the metrics of each model (accuracy, precision, recall, f1-score, roc-auc score) and choose the one with the best performance.\n","* Plot the precision and recall curves (tip: there is a sklearn method for this)\n","* Plot the ROC curve (tip: there is a sklearn method for it)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-emLZGoKbW5E"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7iYH-74sbW5E"},"source":["## Metrics"]},{"cell_type":"markdown","metadata":{"id":"lvTSenEHbW5E"},"source":["**TODO:**\n","\n","* Evaluate the metrics of each model (accuracy, precision, recall, f1-score, roc-auc score) and choose the one with the best performance.\n","* Plot the precision and recall curves (tip: there is a sklearn method for this)\n","* Plot the ROC curve (tip: there is a sklearn method for it)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcFNjqEGbW5F"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"O_tyAYoxbW5F"},"source":["---\n","\n","# Pipeline with ColumnTransformer and GridSearchCV\n","\n","Only toy datasets like the __iris dataset__ will contain only numeric data, as we saw in the previous exercise, the __titanic dataset__ had a variety of different data types and not just numeric data.\n","\n","By having different types of data we will not be able to apply the same transformations to each of them, instead we will have to apply different transformations depending on the type of data.\n","\n","Next we are going to see an example of how to use __ColumnTransformer__ to simplify the application of these different transformations and above all to be able to insert it into a __Pipeline__.\n","\n","Let’s use the toy dataset, which contains both numerical and categorical data, and apply:\n","\n","* Normalize the Income column with MinMaxScaler()\n","* Encode Categorical Columns with OneHotEncoder()\n","* Group the Age column with binning."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1658934645180,"user":{"displayName":"Federico Morales","userId":"06983145799989655383"},"user_tz":180},"id":"oHstTtIKbW5F","outputId":"0ea9bd0c-5471-41b5-b798-19d315ed1bf0"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1309 entries, 0 to 1308\n","Data columns (total 5 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   sex       1309 non-null   object \n"," 1   cabin     295 non-null    object \n"," 2   age       1046 non-null   float64\n"," 3   fare      1308 non-null   float64\n"," 4   survived  1309 non-null   object \n","dtypes: float64(2), object(3)\n","memory usage: 51.3+ KB\n"]}],"source":["titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=False)\n","df_titanic = pd.DataFrame(\n","    data=np.c_[titanic[\"data\"], titanic[\"target\"]],\n","    columns=titanic[\"feature_names\"] + [\"target\"],\n",")\n","df_titanic = df_titanic.rename(columns={\"target\": \"survived\"})\n","df_titanic = df_titanic[[\"sex\", \"cabin\", \"age\", \"fare\", \"survived\"]]\n","\n","df_titanic[\"age\"] = df_titanic[\"age\"].astype(\"float64\")\n","df_titanic[\"fare\"] = df_titanic[\"fare\"].astype(\"float64\")\n","\n","df_titanic.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658934645180,"user":{"displayName":"Federico Morales","userId":"06983145799989655383"},"user_tz":180},"id":"8OIBe-q3bW5F","outputId":"a2c1f32a-2395-44c7-c62f-1e8f06381ded"},"outputs":[{"data":{"text/plain":["sex            0\n","cabin       1014\n","age          263\n","fare           1\n","survived       0\n","dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_titanic.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Sg17EKlbW5G"},"outputs":[],"source":["from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","\n","# Numeric features\n","numeric_transformer = Pipeline(\n","    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",")\n","\n","# Categorical features\n","categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"num\", numeric_transformer, [\"age\", \"fare\"]),\n","        (\"cat\", categorical_transformer, [\"sex\", \"cabin\"]),\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dl35PGKlbW5G"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(\n","    df_titanic.drop(\"survived\", axis=1),\n","    df_titanic.survived,\n","    test_size=0.2,\n","    random_state=0,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1468,"status":"ok","timestamp":1658934779743,"user":{"displayName":"Federico Morales","userId":"06983145799989655383"},"user_tz":180},"id":"7XP70LJCbW5G","outputId":"64069694-a3ec-4cc1-de9a-73c019d4d25d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test score: 0.7977099236641222\n","Best parameters: {'classifier__max_depth': 5}\n","Best score: 0.7927044884939621\n"]}],"source":["my_pipe = Pipeline(\n","    [(\"preprocessor\", preprocessor), (\"classifier\", DecisionTreeClassifier())]\n",")\n","\n","my_params = {\"classifier__max_depth\": [2, 3, 4, 5, 6, 7, 8]}\n","\n","grid = GridSearchCV(my_pipe, my_params, cv=5)\n","grid.fit(X_train, y_train)\n","score = grid.score(X_test, y_test)\n","\n","print(f\"Test score: {score}\")\n","print(f\"Best parameters: {grid.best_params_}\")\n","print(f\"Best score: {grid.best_score_}\")"]},{"cell_type":"markdown","metadata":{"id":"bWKicavhbW5G"},"source":["**TODO:**\n","\n","Using __ColumnTransformer__ and __Pipeline__, build a pipeline where different transformations are applied to different types of data, you can use the Titanic dataset again. Also, do some research about the [FutureUnion](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html) method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zbBw5bybW5G"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"11.1.1 - PRACTICE - Hyperparameter Optimization.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
