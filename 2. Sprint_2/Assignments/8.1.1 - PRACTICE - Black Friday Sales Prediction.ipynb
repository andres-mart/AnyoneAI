{"cells":[{"cell_type":"markdown","id":"15f0ce89","metadata":{"id":"15f0ce89"},"source":["# Machine Learning: Linear Regression\n","\n","## Black Friday Sales Prediction:\n","\n","We are going to use a dataset of product purchases during a Black Friday (in the US). The main idea is to be able to generate a predictor that allows us to predict the `purchase amount`.\n","\n","In order to achieve a good predictor we must apply the different concepts that we have been learning:\n","\n","* `Exploration`\n","* `Feature Engineering`\n","* `Modeling`\n","* `Evaluation`\n","\n","The dataset here is a sample of the transactions made in a retail store. The store wants to know better the customer `purchase` behaviour against different products. The problem is a `regression problem` where we are trying to predict the dependent variable (the amount of purchase) with the help of the information contained in the other variables.\n","\n","### You can try differents Scikit-Learn models from [Linear Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)"]},{"attachments":{},"cell_type":"markdown","id":"3d5d076b","metadata":{},"source":["# Load the dataset"]},{"cell_type":"code","execution_count":null,"id":"317a9a79","metadata":{"id":"317a9a79","outputId":"9e85e5ae-751f-409a-b6c8-466c326b244c"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, RobustScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","data = pd.read_csv(\"https://raw.githubusercontent.com/anyoneai/notebooks/main/datasets/BlackFriday.csv\")\n","data.sample(5)"]},{"attachments":{},"cell_type":"markdown","id":"03f89bdb","metadata":{},"source":["# Explore the dataset"]},{"cell_type":"code","execution_count":null,"id":"3c1af551","metadata":{},"outputs":[],"source":["print(data.shape)\n","print(list(data.columns))"]},{"cell_type":"code","execution_count":null,"id":"18794ff9","metadata":{},"outputs":[],"source":["data.describe()"]},{"cell_type":"code","execution_count":null,"id":"e00d2498","metadata":{},"outputs":[],"source":["# Explore the data\n","data.info()"]},{"cell_type":"code","execution_count":null,"id":"85c7a5d0","metadata":{},"outputs":[],"source":["data.isnull().sum()"]},{"cell_type":"code","execution_count":null,"id":"25475b74","metadata":{},"outputs":[],"source":["mask = np.triu(np.ones_like(data.corr(), dtype=bool))\n","sns.heatmap(data.corr(), mask=mask, annot=True, cmap='coolwarm')"]},{"cell_type":"code","execution_count":null,"id":"b59ac587","metadata":{},"outputs":[],"source":["sns.histplot(data['Purchase'], kde=True)\n","plt.xlabel('Purchase amount')\n","plt.ylabel('Frequency')\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","id":"50179923","metadata":{},"source":["# Feature engineering"]},{"cell_type":"code","execution_count":null,"id":"893c4a9b","metadata":{},"outputs":[],"source":["object_features = data.select_dtypes(include=[\"object\"]).nunique()\n","binary_features = object_features[object_features == 2].index\n","non_binary_features = object_features[object_features != 2].index"]},{"cell_type":"code","execution_count":null,"id":"0ffc50ab","metadata":{},"outputs":[],"source":["object_features"]},{"attachments":{},"cell_type":"markdown","id":"328aef0c","metadata":{},"source":["## Encode features:"]},{"cell_type":"code","execution_count":null,"id":"b674d3fb","metadata":{},"outputs":[],"source":["# We transform binary features:\n","ordinal_encoder = OrdinalEncoder()\n","ordinal_encoder.fit(data[binary_features])\n","bin_encoded = ordinal_encoder.transform(data[binary_features])"]},{"cell_type":"code","execution_count":null,"id":"65ec07e1","metadata":{},"outputs":[],"source":["bin_encoded_df = pd.DataFrame(bin_encoded, columns=binary_features)\n","bin_encoded_df"]},{"cell_type":"code","execution_count":null,"id":"6b372707","metadata":{},"outputs":[],"source":["# Now, we transform non binary features:\n","one_hot_encoder = OneHotEncoder()\n","one_hot_encoder.fit(data[non_binary_features])\n","nonbin_encoded = one_hot_encoder.fit_transform(data[non_binary_features])"]},{"cell_type":"code","execution_count":null,"id":"a083561a","metadata":{},"outputs":[],"source":["# Convert encoded data to a DataFrame\n","nonbin_encoded_df = pd.DataFrame(nonbin_encoded.toarray(), columns=one_hot_encoder.get_feature_names_out(non_binary_features))\n","nonbin_encoded_df\n"]},{"cell_type":"code","execution_count":null,"id":"46b51871","metadata":{},"outputs":[],"source":["# Dummies transformation:\n","## data = pd.get_dummies(data, columns=['Gender', 'Age', 'City_Category', 'Stay_In_Current_City_Years'], drop_first=True)"]},{"attachments":{},"cell_type":"markdown","id":"eddaa24f","metadata":{},"source":["# Handle missing values"]},{"cell_type":"code","execution_count":null,"id":"50524e9c","metadata":{},"outputs":[],"source":["# Create an instance of SimpleImputer to complete missing values:\n","simple_imputer = SimpleImputer()\n","\n","# Replace NaN values in Product_Category_2 and Product_Category_3 columns with the column means:\n","data[['Product_Category_2', 'Product_Category_3']] = simple_imputer.fit_transform(data[['Product_Category_2', 'Product_Category_3']])"]},{"attachments":{},"cell_type":"markdown","id":"3320d39e","metadata":{},"source":["# Scale and normalize"]},{"cell_type":"code","execution_count":null,"id":"c5f6ca3b","metadata":{},"outputs":[],"source":["# Scaling 'Purchase' feature:\n","robust_scaler = RobustScaler()\n","data[\"Purchase\"] = robust_scaler.fit_transform(data[[\"Purchase\"]])"]},{"cell_type":"code","execution_count":null,"id":"ac57bc92","metadata":{},"outputs":[],"source":["# Concatenate bin_encoded, nonbin_encoded, and the remaining features\n","data = pd.concat([bin_encoded, nonbin_encoded, data.drop(columns=binary_features.union(non_binary_features)).values], axis=1)\n","\n","# Create a list of the feature names for the new dataframe\n","feature_names = list(binary_features) + list(non_binary_features) + list(data.columns.drop(binary_features).drop(non_binary_features))\n","\n","# Convert the concatenated numpy array to a pandas dataframe with column names\n","df = pd.DataFrame(data, columns=feature_names)\n"]},{"cell_type":"code","execution_count":null,"id":"75063901","metadata":{},"outputs":[],"source":["data = np.concatenate(\n","    [\n","        bin_encoded,\n","        nonbin_encoded,\n","        data.drop(\n","            columns=binary_features.union(non_binary_features)\n","        ).values,\n","    ],\n","    axis=1,\n",")"]},{"cell_type":"code","execution_count":null,"id":"d6f4f0ff","metadata":{},"outputs":[],"source":["pd.DataFrame(data_encoded)\n"]},{"cell_type":"code","execution_count":null,"id":"6a7deb26","metadata":{},"outputs":[],"source":["column_names = list(binary_features) + list(non_binary_features) + list(data.columns)\n","df = pd.DataFrame(data_encoded, columns = column_names)"]},{"cell_type":"code","execution_count":null,"id":"0fd11386","metadata":{},"outputs":[],"source":["# We drop unwanted columns:\n","data.drop(['User_ID', 'Product_ID'], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"26dea5f4","metadata":{},"outputs":[],"source":["# We split the dataset into training and testing sets:\n","X = data.drop(['Purchase'], axis=1)\n","y = data['Purchase']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n","\n","# We create the model:\n","lr = LinearRegression()\n","lr.fit(X_train, y_train)\n","\n","# Finally, we evaluate the model:\n","y_pred = lr.predict(X_test)\n","rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","r2 = r2_score(y_test,y_pred)\n","print('Root Mean Squared Error:', rmse)\n","print('R-squared:', r2)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"8.1.1 - PRACTICE - Black Friday Sales Prediction.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":5}
